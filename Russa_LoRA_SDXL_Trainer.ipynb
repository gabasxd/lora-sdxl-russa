
# @title Fine-Tune SDXL com LoRA - Modelo Virtual Russa

# 1. Instalar dependências
!pip install --upgrade diffusers transformers accelerate safetensors peft bitsandbytes xformers trl datasets einops

# 2. Preparar diretórios
import os
from zipfile import ZipFile

dataset_zip = "/content/modelo_russa_dataset.zip"
dataset_path = "/content/training_images"
os.makedirs(dataset_path, exist_ok=True)

# Faça upload do .zip no Colab
from google.colab import files
uploaded = files.upload()
with ZipFile("modelo_russa_dataset.zip", 'r') as zip_ref:
    zip_ref.extractall(dataset_path)

# 3. Imports
import torch
from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler
from peft import get_peft_model, LoraConfig, TaskType
from transformers import CLIPTokenizer
from datasets import Dataset
from torchvision import transforms
from PIL import Image
from tqdm import tqdm

# 4. Configuração
MODEL_NAME = "stabilityai/stable-diffusion-xl-base-1.0"
SAVE_PATH = "./sdxl_lora_model"
PROMPT_TEMPLATE = "a beautiful russian redhead model, full body, realistic, {pose_desc}"

pose_descriptions = [
    "posing in bed, sensual look",
    "standing near the window, backlight",
    "laying on the couch, intimate lighting",
    "bikini at the beach, natural body",
    "in front of a mirror, confident pose",
    "close-up, soft smile",
    "brushing hair, relaxed mood"
]

# 5. Carregar modelo SDXL
pipe = StableDiffusionXLPipeline.from_pretrained(
    MODEL_NAME,
    torch_dtype=torch.float16,
    variant="fp16",
    use_safetensors=True
).to("cuda")
pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)

# 6. LoRA
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["attn1", "attn2", "ff"],
    lora_dropout=0.05,
    bias="none",
    task_type=TaskType.TEXT_TO_IMAGE
)
pipe = get_peft_model(pipe, lora_config)

# 7. Dataset
def load_custom_dataset(folder):
    images, prompts = [], []
    files = [f for f in os.listdir(folder) if f.endswith('.png') or f.endswith('.jpg')]
    for i, file in enumerate(files):
        img = Image.open(os.path.join(folder, file)).convert("RGB")
        images.append(img)
        prompts.append(PROMPT_TEMPLATE.format(pose_desc=pose_descriptions[i % len(pose_descriptions)]))
    return Dataset.from_dict({"image": images, "prompt": prompts})

dataset = load_custom_dataset(dataset_path)

# 8. DataLoader
transform = transforms.Compose([
    transforms.Resize((1024, 1024)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

def collate_fn(batch):
    pixel_values = torch.stack([transform(ex["image"]) for ex in batch])
    prompts = [ex["prompt"] for ex in batch]
    return {"pixel_values": pixel_values, "prompt": prompts}

from torch.utils.data import DataLoader
train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)

# 9. Treinamento
optimizer = torch.optim.AdamW(pipe.parameters(), lr=1e-5)

epochs = 5
pipe.train()
for epoch in range(epochs):
    for batch in tqdm(train_dataloader):
        outputs = pipe(
            prompt=batch["prompt"],
            images=batch["pixel_values"].to("cuda"),
            return_loss=True
        )
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

# 10. Salvar modelo
pipe.save_pretrained(SAVE_PATH, safe_serialization=True)

# 11. Testar
pipe.eval()
prompt = "a beautiful redhead russian model, lying in bed, natural body, realistic light"
image = pipe(prompt=prompt, num_inference_steps=30, guidance_scale=7.5).images[0]
image.save("amostra_treino.png")
